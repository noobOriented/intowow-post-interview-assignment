{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded latent factors of movies.\n"
     ]
    }
   ],
   "source": [
    "MYPROJECT = '/Users/jsaon/Work/Interview/Intowow/MovieRecommendation/'\n",
    "import os, sys\n",
    "sys.path.insert(0, MYPROJECT)\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"local_settings.py\")\n",
    "import django\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from django.utils import timezone\n",
    "from django.db.models import Avg, Count\n",
    "from django.contrib.auth import get_user_model\n",
    "User = get_user_model()\n",
    "from django.core.cache import cache\n",
    "\n",
    "from movie.models import Movie, Genre, Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link_df = pd.read_csv('./ml-latest/links.csv')\n",
    "movie_df = pd.read_csv('./ml-latest/movies.csv')\n",
    "rating_df = pd.read_csv('./ml-latest/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_df = pd.merge(movie_df, link_df)\n",
    "movie_df['tmdbId'] = movie_df['tmdbId'].fillna(0).astype(int)\n",
    "movie_df['pub_year'] = movie_df['title'].str.extract('\\(([0-9]+)\\)$', expand=False).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "- Drop the movies before 2010\n",
    "- Drop the movies with less than 10 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_df = movie_df[movie_df['pub_year'] >= 2010]\n",
    "rating_df = rating_df.merge(movie_df, on='movieId', how='inner')[rating_df.columns]\n",
    "rating_count = rating_df.groupby('movieId').size().to_frame(name='count').reset_index()\n",
    "movie_df = movie_df.merge(rating_count, how='inner')\n",
    "movie_df = movie_df[movie_df['count'] >= 10]\n",
    "rating_df = rating_df.merge(movie_df, on='movieId', how='inner')[rating_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies after cleaning:  5127\n",
      "Number of ratings after cleaning:  1892265\n"
     ]
    }
   ],
   "source": [
    "print('Number of movies after cleaning: ', len(movie_df))\n",
    "print('Number of ratings after cleaning: ', len(rating_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_df = movie_df.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remap id\n",
    "- Make the id dense, more suitable to apply embeddings\n",
    "\n",
    "- Drop the user whose ratings were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_id_dict = {}\n",
    "\n",
    "for idx, row in movie_df.iterrows():\n",
    "    movie_id_dict[row.movieId] = idx + 1\n",
    "\n",
    "movie_df['movieId'] = movie_df['movieId'].apply(lambda x: movie_id_dict[x])\n",
    "rating_df['movieId'] = rating_df['movieId'].apply(lambda x: movie_id_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_id_dict = {userId: i for i, userId in enumerate(rating_df['userId'].unique(), 1)}\n",
    "rating_df['userId'] = rating_df['userId'].apply(lambda x: user_id_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users after cleaning:  66323\n"
     ]
    }
   ],
   "source": [
    "print('Number of users after cleaning: ', len(user_id_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_df.to_csv('./ml-latest/movies_preprocessed.csv')\n",
    "rating_df.to_csv('./ml-latest/ratings_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genres_set = set([genre for genres in movie_df['genres'].str.split('|') for genre in genres])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_dict = {}\n",
    "for genre_text in genres_set:\n",
    "    g = Genre(genre_text=genre_text)\n",
    "    genre_dict[genre_text] = g\n",
    "    g.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_dict = {}\n",
    "for _, row in movie_df.iterrows():\n",
    "    m = Movie(title=row.title, imdb_id=row.imdbId)\n",
    "    if row.tmdbId > 0:\n",
    "        m.tmdb_id = row.tmdbId\n",
    "    if row.pub_year > 0:\n",
    "        m.pub_year = row.pub_year\n",
    "        \n",
    "    m.save()\n",
    "    for genre_text in row.genres.split('|'):\n",
    "        m.genres.add(genre_dict[genre_text])\n",
    "        \n",
    "    movie_dict[row.movieId] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _, row in rating_df.iterrows():\n",
    "    pub_date = timezone.make_aware(datetime.fromtimestamp(row.timestamp), timezone=timezone.get_current_timezone())\n",
    "    rating = Rating(score=row.rating, pub_date=pub_date)\n",
    "    rating.movie = movie_dict[row.movieId]\n",
    "    rating.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = 66323\n",
    "n_movies = 5127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Matrix Factorization Model\n",
    "\n",
    "- Prediction\n",
    "$$\\widehat R_{u, i} = x_u y_i + \\alpha_u + \\beta_i + \\mu$$\n",
    "\n",
    "$$\\mu = \\frac{1}{N} \\sum R_{u,i}$$\n",
    "\n",
    "- Loss Function\n",
    "$$\\mathcal{L} = \\frac{1}{2}(\\sum_{(u, i)\\in R}(\\widehat R_{u, i} - R_{u, i})^2 + \\lambda(\\sum_u \\|x_u\\|^2 + \\alpha_u^2 + \\sum_i \\|y_i\\|^2 + \\beta_i^2))$$\n",
    "\n",
    "- Gradient\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial x_u} = \\sum_{i}(\\widehat R_{u, i} - R_{u, i})y_i + \\lambda x_u$$\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial y_i} = \\sum_{u}(\\widehat R_{u, i} - R_{u, i})x_u + \\lambda y_i$$\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\alpha_u} = \\sum_{i}\\widehat R_{u, i} - R_{u, i}$$\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\beta_i} = \\sum_{u}\\widehat R_{u, i} - R_{u, i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras import regularizers, Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Reshape, Lambda, Dot, Add, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.constraints import max_norm\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cf_model(n_users, n_movies, k_factors):\n",
    "    user_id = Input(shape=(1,), dtype='int32', name='user_id')\n",
    "    movie_id = Input(shape=(1,), dtype='int32', name='movie_id')\n",
    "    \n",
    "    weight_u = Embedding(n_users + 1, k_factors,\n",
    "                         embeddings_initializer=RandomNormal(stddev=np.sqrt(1 / k_factors)),\n",
    "                         embeddings_regularizer=regularizers.l2(0.02 / n_users),\n",
    "                         input_length=1, name='user_weight')(user_id)\n",
    "    weight_m = Embedding(n_movies + 1, k_factors,\n",
    "                         embeddings_initializer=RandomNormal(stddev=np.sqrt(1 / k_factors)),\n",
    "                         embeddings_regularizer=regularizers.l2(0.02 / n_movies),\n",
    "                         input_length=1, name='movie_weight')(movie_id)\n",
    "    \n",
    "    bias_u = Embedding(n_users + 1, 1, embeddings_initializer='zero',\n",
    "                       embeddings_regularizer=regularizers.l2(0.02 / n_users),\n",
    "                       input_length=1, name='user_bias')(user_id)\n",
    "    bias_m = Embedding(n_movies + 1, 1, embeddings_initializer='zero',\n",
    "                       embeddings_regularizer=regularizers.l2(0.02 / n_movies),\n",
    "                       input_length=1, name='movie_bias')(movie_id)\n",
    "    \n",
    "    score = Dot(axes=2, name='dot')([weight_u, weight_m])\n",
    "    score = Add(name='add')([score, bias_u, bias_m])\n",
    "    score = Reshape((1,), name='reshape')(score)\n",
    "    model = Model(inputs=(user_id, movie_id), outputs=score)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_factors = 30\n",
    "cf_model = get_cf_model(n_users, n_movies, k_factors)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred), axis=-1))\n",
    "\n",
    "cf_model.compile(loss='mse', optimizer='adam', metrics=[rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_id (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_weight (Embedding)         (None, 1, 30)        1989720     user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "movie_weight (Embedding)        (None, 1, 30)        153840      movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 1)         0           user_weight[0][0]                \n",
      "                                                                 movie_weight[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "user_bias (Embedding)           (None, 1, 1)         66324       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "movie_bias (Embedding)          (None, 1, 1)         5128        movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1, 1)         0           dot[0][0]                        \n",
      "                                                                 user_bias[0][0]                  \n",
      "                                                                 movie_bias[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1)            0           add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 2,215,012\n",
      "Trainable params: 2,215,012\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5533318536251528"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [rating_df['userId'].values, rating_df['movieId'].values]\n",
    "y = rating_df['rating'].values\n",
    "rating_mean = np.mean(y)\n",
    "rating_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1797651 samples, validate on 94614 samples\n",
      "Epoch 1/20\n",
      "1797651/1797651 [==============================] - 523s 291us/step - loss: 0.8542 - rmse: 0.6925 - val_loss: 1.1381 - val_rmse: 0.7954\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.13814, saving model to ./ml-latest/model_best.hdf5\n",
      "Epoch 2/20\n",
      "1797651/1797651 [==============================] - 542s 302us/step - loss: 0.6384 - rmse: 0.5848 - val_loss: 1.0871 - val_rmse: 0.7767\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.13814 to 1.08708, saving model to ./ml-latest/model_best.hdf5\n",
      "Epoch 3/20\n",
      " 140544/1797651 [=>............................] - ETA: 8:34 - loss: 0.5349 - rmse: 0.5248"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-07c9340419ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m cf_model.fit(x, y - rating_mean, epochs=20, batch_size=256,\n\u001b[0;32m----> 6\u001b[0;31m              validation_split=0.05, callbacks=[checkpoint]);\n\u001b[0m",
      "\u001b[0;32m/Users/jsaon/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/jsaon/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jsaon/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jsaon/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jsaon/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jsaon/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/jsaon/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jsaon/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('./ml-latest/model_best.hdf5', monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "\n",
    "cf_model.fit(x, y - rating_mean, epochs=20, batch_size=256,\n",
    "             validation_split=0.05, callbacks=[checkpoint]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cf_model = load_model('./ml-latest/model_best.hdf5', custom_objects={'rmse': rmse})\n",
    "movie_vec = np.zeros((n_movies + 1, 1 + 30))\n",
    "\n",
    "movie_vec[:, 1:] = cf_model.get_layer('movie_weight').get_weights()[0]\n",
    "movie_vec[:, 0:1] = cf_model.get_layer('movie_bias').get_weights()[0]\n",
    "\n",
    "user_vec = np.zeros((n_users + 1, 1 + 30))\n",
    "\n",
    "user_vec[:, 1:] = cf_model.get_layer('user_weight').get_weights()[0]\n",
    "user_vec[:, 0:1] = cf_model.get_layer('user_bias').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4818730933288471"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.dot(movie_vec[:, 1:], user_vec[:, 1:].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_k(title, k):\n",
    "    m = Movie.objects.get(title=title)\n",
    "    print(title)\n",
    "    for genre in m.genres.all():\n",
    "        print('-', genre)\n",
    "    print()\n",
    "    v = movie_vec[m.id, :]\n",
    "    score = np.dot(movie_vec[:, 1:], v[1:])\n",
    "    indices = np.argsort(score)[-1:-k-1:-1]\n",
    "    for movie in Movie.objects.filter(id__in=indices):\n",
    "        print(movie)\n",
    "        for genre in movie.genres.all():\n",
    "            print('    -', genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Out (2015)\n",
      "- Adventure\n",
      "- Animation\n",
      "- Children\n",
      "- Comedy\n",
      "- Drama\n",
      "- Fantasy\n",
      "\n",
      "How to Train Your Dragon (2010)\n",
      "    - Adventure\n",
      "    - Animation\n",
      "    - Children\n",
      "    - Fantasy\n",
      "    - IMAX\n",
      "Toy Story 3 (2010)\n",
      "    - Adventure\n",
      "    - Animation\n",
      "    - Children\n",
      "    - Comedy\n",
      "    - Fantasy\n",
      "    - IMAX\n",
      "Tangled (2010)\n",
      "    - Animation\n",
      "    - Children\n",
      "    - Comedy\n",
      "    - Fantasy\n",
      "    - IMAX\n",
      "    - Musical\n",
      "    - Romance\n",
      "Wreck-It Ralph (2012)\n",
      "    - Animation\n",
      "    - Comedy\n",
      "Frozen (2013)\n",
      "    - Adventure\n",
      "    - Animation\n",
      "    - Comedy\n",
      "    - Fantasy\n",
      "    - Musical\n",
      "    - Romance\n",
      "The Lego Movie (2014)\n",
      "    - Action\n",
      "    - Adventure\n",
      "    - Animation\n",
      "    - Children\n",
      "    - Comedy\n",
      "    - Fantasy\n",
      "How to Train Your Dragon 2 (2014)\n",
      "    - Action\n",
      "    - Adventure\n",
      "    - Animation\n",
      "Big Hero 6 (2014)\n",
      "    - Action\n",
      "    - Animation\n",
      "    - Comedy\n",
      "Inside Out (2015)\n",
      "    - Adventure\n",
      "    - Animation\n",
      "    - Children\n",
      "    - Comedy\n",
      "    - Drama\n",
      "    - Fantasy\n",
      "Zootopia (2016)\n",
      "    - Action\n",
      "    - Adventure\n",
      "    - Animation\n",
      "    - Children\n",
      "    - Comedy\n"
     ]
    }
   ],
   "source": [
    "get_top_k('Inside Out (2015)', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for movie in Movie.objects.all():\n",
    "    movie.latent_factor = movie_vec[movie.id, :].tolist()\n",
    "    movie.save(update_fields=['latent_factor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./ml-latest/movie_latent_factors.npy', movie_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
